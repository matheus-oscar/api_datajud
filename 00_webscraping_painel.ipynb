{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b9f4053",
   "metadata": {},
   "source": [
    "#### Link para download\n",
    "- https://api-csvr.stg.cloud.cnj.jus.br/download_csv?tribunal=TJSP&indicador=&oj=&grau=&municipio=&ambiente=csv_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bcc77d",
   "metadata": {},
   "source": [
    "#### FUN√á√ïES APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370eb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from time import time, sleep\n",
    "\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def download_with_retry(pasta_destino, nome_arquivo_zip, \n",
    "                        url=\"https://api-csvr.stg.cloud.cnj.jus.br/download_csv?tribunal=TJSP&indicador=&oj=&grau=&municipio=&ambiente=csv_p\", \n",
    "                        max_retries=3, chunk_size=1024*1024):\n",
    "\n",
    "    os.makedirs(pasta_destino, exist_ok=True)\n",
    "    output_file = os.path.join(pasta_destino, nome_arquivo_zip)\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"üì¶ Arquivo j√° existe: {output_file}\")\n",
    "        return output_file\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Referer\": \"https://justica-em-numeros.cnj.jus.br/\"\n",
    "    }\n",
    "\n",
    "    retry_strategy = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\"]\n",
    "    )\n",
    "\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        print(f\"\\n Tentativa {attempt} de {max_retries}...\")\n",
    "        try:\n",
    "            with requests.Session() as session:\n",
    "                session.mount(\"https://\", adapter)\n",
    "                session.mount(\"http://\", adapter)\n",
    "\n",
    "                with session.get(url, headers=headers, stream=True, timeout=180) as r:\n",
    "                    r.raise_for_status()\n",
    "                    total_size = int(r.headers.get(\"content-length\", 0))\n",
    "                    downloaded = 0\n",
    "                    start = time()\n",
    "\n",
    "                    with open(output_file, \"wb\") as f:\n",
    "                        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                            if chunk:\n",
    "                                f.write(chunk)\n",
    "                                downloaded += len(chunk)\n",
    "                                elapsed = time() - start\n",
    "                                speed = downloaded / elapsed\n",
    "                                percent = (downloaded / total_size) * 100\n",
    "                                eta = (total_size - downloaded) / speed if speed else 0\n",
    "\n",
    "                                print(\n",
    "                                    f\"\\r{downloaded / (1024**2):.2f} MB \"\n",
    "                                    f\"({percent:.2f}%) | Velocidade: {speed / (1024**2):.2f} MB/s | ETA: {eta:.1f}s\",\n",
    "                                    end=\"\"\n",
    "                                )\n",
    "\n",
    "                    print(\"\\n‚úÖ Download conclu√≠do com sucesso.\")\n",
    "                    return output_file\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Erro: {e}\")\n",
    "            sleep(5)\n",
    "\n",
    "    print(\"\\n‚ùå Todas as tentativas de download falharam.\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46736eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descompactar_arquivos(zip_path, pasta_destino):\n",
    "    print(f\"Iniciando extra√ß√£o de: {zip_path}\")\n",
    "    os.makedirs(pasta_destino, exist_ok=True)\n",
    "\n",
    "    inicio = time()\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        lista_arquivos = zip_ref.namelist()\n",
    "        print(f\"üìÅ Total de arquivos no ZIP: {len(lista_arquivos)}\")\n",
    "\n",
    "        with tqdm(total=len(lista_arquivos), desc=\"Extraindo\", unit=\"arquivo\") as pbar:\n",
    "            for nome_arquivo in lista_arquivos:\n",
    "                zip_ref.extract(nome_arquivo, pasta_destino)\n",
    "                pbar.set_postfix_str(nome_arquivo[-60:])\n",
    "                pbar.update(1)\n",
    "\n",
    "    duracao = time() - inicio\n",
    "    print(f\"\\nExtra√ß√£o conclu√≠da em {duracao:.2f} segundos.\")\n",
    "    print(f\"üìÇ Arquivos extra√≠dos em: {pasta_destino}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba26dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_csvs(pasta_csvs, pasta_saida, chunksize=500_000):\n",
    "    os.makedirs(pasta_saida, exist_ok=True)\n",
    "    grupos = defaultdict(list)\n",
    "\n",
    "    print(\"Varredura inicial dos arquivos...\")\n",
    "    for arquivo in os.listdir(pasta_csvs):\n",
    "        if not arquivo.endswith(\".csv\"):\n",
    "            continue\n",
    "        caminho = os.path.join(pasta_csvs, arquivo)\n",
    "\n",
    "        if arquivo.startswith(\"TJSP_tbl_correg\"):\n",
    "            print(f\"üìÅ Detectado TJSP_tbl_correg: {arquivo}\")\n",
    "            inicio = time()\n",
    "            df = pd.read_csv(caminho, sep=';', low_memory=False)\n",
    "            duracao = time() - inicio\n",
    "            print(f\"Linhas: {len(df):,} | Tempo: {duracao:.2f}s\")\n",
    "\n",
    "            destino = os.path.join(pasta_saida, \"TJSP_tbl_correg.csv\")\n",
    "            df.to_csv(destino, index=False, sep=';', encoding=\"utf-8-sig\")\n",
    "            print(f\"‚úÖ Salvo: {destino}\")\n",
    "            continue\n",
    "\n",
    "        # Detecta chave por regex\n",
    "        if re.search(r\"TJSP_CN_.+\\.csv$\", arquivo):\n",
    "            chave = \"TJSP_CN\"\n",
    "        elif re.search(r\"TJSP_CPL_15anos_.+\\.csv$\", arquivo):\n",
    "            chave = \"TJSP_CPL_15anos\"\n",
    "        elif re.search(r\"TJSP_CPL_.+\\.csv$\", arquivo):\n",
    "            chave = \"TJSP_CPL\"\n",
    "        elif re.search(r\"TJSP_Sent_.+\\.csv$\", arquivo):\n",
    "            chave = \"TJSP_Sent\"\n",
    "        elif re.search(r\"TJSP_TBaix_.+\\.csv$\", arquivo):\n",
    "            chave = \"TJSP_TBaix\"\n",
    "        else:\n",
    "            print(f\"Ignorado (sem padr√£o): {arquivo}\")\n",
    "            continue\n",
    "\n",
    "        grupos[chave].append(caminho)\n",
    "\n",
    "    print(\"\\nIniciando agrupamento por prefixo com chunks...\\n\")\n",
    "    for grupo, arquivos in grupos.items():\n",
    "        if not arquivos:\n",
    "            continue\n",
    "\n",
    "        destino = os.path.join(pasta_saida, f\"{grupo}.csv\")\n",
    "        print(f\"{grupo} ‚Üí {len(arquivos)} arquivos\")\n",
    "        inicio_grupo = time()\n",
    "        total_linhas = 0\n",
    "        is_first_chunk = True\n",
    "\n",
    "        for caminho in arquivos:\n",
    "            print(f\"Processando: {os.path.basename(caminho)}\")\n",
    "            t1 = time()\n",
    "\n",
    "            for i, chunk in enumerate(pd.read_csv(caminho, sep=';', chunksize=chunksize, low_memory=False)):\n",
    "                chunk.to_csv(destino, mode='w' if is_first_chunk else 'a', index=False, header=is_first_chunk, sep=';')\n",
    "                is_first_chunk = False\n",
    "                total_linhas += len(chunk)\n",
    "                print(f\"Chunk {i+1} ‚Üí {len(chunk):,} linhas\")\n",
    "\n",
    "            t2 = time()\n",
    "            print(f\"Arquivo processado em {t2 - t1:.2f}s\")\n",
    "\n",
    "        duracao_total = time() - inicio_grupo\n",
    "        print(f\"‚úÖ {grupo}.csv salvo | Total: {total_linhas:,} linhas | ‚è±Ô∏è {duracao_total:.2f}s\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
