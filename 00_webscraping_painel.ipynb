{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b9f4053",
   "metadata": {},
   "source": [
    "#### Link para download\n",
    "- https://api-csvr.stg.cloud.cnj.jus.br/download_csv?tribunal=TJSP&indicador=&oj=&grau=&municipio=&ambiente=csv_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bcc77d",
   "metadata": {},
   "source": [
    "#### FUN√á√ïES APP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "370eb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "from time import time, sleep\n",
    "\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def download_with_retry(pasta_destino, nome_arquivo_zip, \n",
    "                        url=\"https://api-csvr.stg.cloud.cnj.jus.br/download_csv?tribunal=TJSP&indicador=&oj=&grau=&municipio=&ambiente=csv_p\", \n",
    "                        max_retries=3, chunk_size=1024*1024):\n",
    "\n",
    "    os.makedirs(pasta_destino, exist_ok=True)\n",
    "    output_file = os.path.join(pasta_destino, nome_arquivo_zip)\n",
    "\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"üì¶ Arquivo j√° existe: {output_file}\")\n",
    "        return output_file\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0\",\n",
    "        \"Referer\": \"https://justica-em-numeros.cnj.jus.br/\"\n",
    "    }\n",
    "\n",
    "    retry_strategy = Retry(\n",
    "        total=5,\n",
    "        backoff_factor=5,\n",
    "        status_forcelist=[500, 502, 503, 504],\n",
    "        allowed_methods=[\"GET\"]\n",
    "    )\n",
    "\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        print(f\"\\n Tentativa {attempt} de {max_retries}...\")\n",
    "        try:\n",
    "            with requests.Session() as session:\n",
    "                session.mount(\"https://\", adapter)\n",
    "                session.mount(\"http://\", adapter)\n",
    "\n",
    "                with session.get(url, headers=headers, stream=True, timeout=180) as r:\n",
    "                    r.raise_for_status()\n",
    "                    total_size = int(r.headers.get(\"content-length\", 0))\n",
    "                    downloaded = 0\n",
    "                    start = time()\n",
    "\n",
    "                    with open(output_file, \"wb\") as f:\n",
    "                        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                            if chunk:\n",
    "                                f.write(chunk)\n",
    "                                downloaded += len(chunk)\n",
    "                                elapsed = time() - start\n",
    "                                speed = downloaded / elapsed\n",
    "                                percent = (downloaded / total_size) * 100\n",
    "                                eta = (total_size - downloaded) / speed if speed else 0\n",
    "\n",
    "                                print(\n",
    "                                    f\"\\r{downloaded / (1024**2):.2f} MB \"\n",
    "                                    f\"({percent:.2f}%) | Velocidade: {speed / (1024**2):.2f} MB/s | ETA: {eta:.1f}s\",\n",
    "                                    end=\"\"\n",
    "                                )\n",
    "\n",
    "                    print(\"\\n‚úÖ Download conclu√≠do com sucesso.\")\n",
    "                    return output_file\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Erro: {e}\")\n",
    "            sleep(5)\n",
    "\n",
    "    print(\"\\n‚ùå Todas as tentativas de download falharam.\")\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fbe35c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tentativa 1 de 3...\n",
      "‚¨áÔ∏è 2307.69 MB (100.00%) | Velocidade: 1.08 MB/s | ETA: 0.0sss\n",
      "‚úÖ Download conclu√≠do com sucesso.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data-raw2307\\\\TJSP_2307.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_with_retry(\"data-raw2307\", 'TJSP_2307.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46736eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def descompactar_arquivos(zip_path, pasta_destino):\n",
    "    print(f\"Iniciando extra√ß√£o de: {zip_path}\")\n",
    "    os.makedirs(pasta_destino, exist_ok=True)\n",
    "\n",
    "    inicio = time()\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        lista_arquivos = zip_ref.namelist()\n",
    "        print(f\"üìÅ Total de arquivos no ZIP: {len(lista_arquivos)}\")\n",
    "\n",
    "        with tqdm(total=len(lista_arquivos), desc=\"Extraindo\", unit=\"arquivo\") as pbar:\n",
    "            for nome_arquivo in lista_arquivos:\n",
    "                zip_ref.extract(nome_arquivo, pasta_destino)\n",
    "                pbar.set_postfix_str(nome_arquivo[-60:])\n",
    "                pbar.update(1)\n",
    "\n",
    "    duracao = time() - inicio\n",
    "    print(f\"\\nExtra√ß√£o conclu√≠da em {duracao:.2f} segundos.\")\n",
    "    print(f\"üìÇ Arquivos extra√≠dos em: {pasta_destino}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba26dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrupar_csvs(pasta_csvs, pasta_saida, chunksize=500_000):\n",
    "    os.makedirs(pasta_saida, exist_ok=True)\n",
    "    grupos = defaultdict(list)\n",
    "\n",
    "    print(\"Varredura inicial dos arquivos...\")\n",
    "    for arquivo in os.listdir(pasta_csvs):\n",
    "        if not arquivo.endswith(\".csv\"):\n",
    "            continue\n",
    "        caminho = os.path.join(pasta_csvs, arquivo)\n",
    "\n",
    "        if arquivo.startswith(\"TJSP_tbl_correg\"):\n",
    "            print(f\"üìÅ Detectado TJSP_tbl_correg: {arquivo}\")\n",
    "            inicio = time()\n",
    "            df = pd.read_csv(caminho, sep=';', low_memory=False)\n",
    "            duracao = time() - inicio\n",
    "            print(f\"Linhas: {len(df):,} | Tempo: {duracao:.2f}s\")\n",
    "\n",
    "            destino = os.path.join(pasta_saida, \"TJSP_tbl_correg.csv\")\n",
    "            df.to_csv(destino, index=False, sep=';', encoding=\"utf-8-sig\")\n",
    "            print(f\"‚úÖ Salvo: {destino}\")\n",
    "            continue\n",
    "\n",
    "        # Detecta chave por regex\n",
    "        if re.search(r\"TJSP_CN_.+\\.csv$\", arquivo):\n",
    "            chave = \"TJSP_CN\"\n",
    "        elif re.search(r\"TJSP_CPL_15anos_.+\\.csv$\", arquivo):\n",
    "            chave = \"TJSP_CPL_15anos\"\n",
    "        elif re.search(r\"TJSP_CPL_.+\\.csv$\", arquivo):\n",
    "            chave = \"TJSP_CPL\"\n",
    "        elif re.search(r\"TJSP_Sent_.+\\.csv$\", arquivo):\n",
    "            chave = \"TJSP_Sent\"\n",
    "        elif re.search(r\"TJSP_TBaix_.+\\.csv$\", arquivo):\n",
    "            chave = \"TJSP_TBaix\"\n",
    "        else:\n",
    "            print(f\"Ignorado (sem padr√£o): {arquivo}\")\n",
    "            continue\n",
    "\n",
    "        grupos[chave].append(caminho)\n",
    "\n",
    "    print(\"\\nIniciando agrupamento por prefixo com chunks...\\n\")\n",
    "    for grupo, arquivos in grupos.items():\n",
    "        if not arquivos:\n",
    "            continue\n",
    "\n",
    "        destino = os.path.join(pasta_saida, f\"{grupo}.csv\")\n",
    "        print(f\"{grupo} ‚Üí {len(arquivos)} arquivos\")\n",
    "        inicio_grupo = time()\n",
    "        total_linhas = 0\n",
    "        is_first_chunk = True\n",
    "\n",
    "        for caminho in arquivos:\n",
    "            print(f\"Processando: {os.path.basename(caminho)}\")\n",
    "            t1 = time()\n",
    "\n",
    "            for i, chunk in enumerate(pd.read_csv(caminho, sep=';', chunksize=chunksize, low_memory=False)):\n",
    "                chunk.to_csv(destino, mode='w' if is_first_chunk else 'a', index=False, header=is_first_chunk, sep=';')\n",
    "                is_first_chunk = False\n",
    "                total_linhas += len(chunk)\n",
    "                print(f\"Chunk {i+1} ‚Üí {len(chunk):,} linhas\")\n",
    "\n",
    "            t2 = time()\n",
    "            print(f\"Arquivo processado em {t2 - t1:.2f}s\")\n",
    "\n",
    "        duracao_total = time() - inicio_grupo\n",
    "        print(f\"‚úÖ {grupo}.csv salvo | Total: {total_linhas:,} linhas | ‚è±Ô∏è {duracao_total:.2f}s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "241888cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando extra√ß√£o de: data-raw2307/TJSP_2307.zip\n",
      "üìÅ Total de arquivos no ZIP: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraindo: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 21/21 [03:05<00:00,  8.83s/arquivo, TJSP_TBaix_4-4.csv]     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extra√ß√£o conclu√≠da em 185.36 segundos.\n",
      "üìÇ Arquivos extra√≠dos em: data-raw2307/dados-extraidos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "descompactar_arquivos('data-raw2307/TJSP_2307.zip', 'data-raw2307/dados-extraidos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb55921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "parquet = pd.read_parquet('./app10/dados-processos/tjsp_processos.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921554ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet.Processo.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ec8c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "api_datajud = pd.read_parquet('./app10/resultado-api/lotes/lote_7374.parquet')\n",
    "\n",
    "api_datajud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e84fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_datajud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f610d4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_datajud.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60cd7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_datajud.numeroProcesso.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1bc96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_datajud[api_datajud['numeroProcesso'] == '15020806020248260408']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02749d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_datajud"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
